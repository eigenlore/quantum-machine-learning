\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Classical machine learning}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Support vector machine}{2}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Linear SVM}{2}{}\protected@file@percent }
\newlabel{margin definition}{{1}{2}{}{}{}}
\newlabel{constraint hard margin}{{5}{3}{}{}{}}
\newlabel{alpha def}{{6}{3}{}{}{}}
\newlabel{dual problem SVM}{{7}{3}{}{}{}}
\newlabel{decision boundary svm}{{11}{4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SVM decision boundary and margin border, fitted on a 2 feature mock dataset of 200 instances.}}{5}{}\protected@file@percent }
\newlabel{fig:classical svm mock}{{1}{5}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Kernel SVM}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Higly non-linear 2 feature mock dataset with 200 instances.}}{6}{}\protected@file@percent }
\newlabel{fig:classical svm circles}{{2}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Highly non-linear mock dataset in the feature space after the application of the feature map $\phi $. We observe now that the dataset is linearly separable.}}{7}{}\protected@file@percent }
\newlabel{fig:classical svm circle 3d}{{3}{7}{}{}{}}
\newlabel{kernel max}{{16}{7}{}{}{}}
\newlabel{kernel prodiction}{{17}{8}{}{}{}}
\newlabel{kernel max K}{{19}{8}{}{}{}}
\newlabel{kernel prodiction K}{{20}{8}{}{}{}}
\newlabel{polykernel ex}{{21}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Highly non-linear mock dataset decision boundary, fitted with a SVM using kernel of eq. (\ref {polykernel ex}). The white and black areas are the two predicted classes. We observe how, using the kernel, we obtained a non-linear decision boundary.}}{10}{}\protected@file@percent }
\newlabel{fig:classical svm circle decision boundary}{{4}{10}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Quantum machine learning}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Quantum Support Vector Machine}{10}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Quantum feature map and Quantum Kernels}{10}{}\protected@file@percent }
\newlabel{circuit}{{26}{11}{}{}{}}
\newlabel{frequency}{{27}{12}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.2}Quantum encoding circuits}{12}{}\protected@file@percent }
\newlabel{ZZ}{{37}{14}{}{}{}}
\newlabel{coeff Z}{{39}{15}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Z feature map, with 2 qubits and 2 features, decomposed in terms of elementary gates. The gate $P$ is defined as $P(\phi ) = (1,0; 0, e^{i\phi })$. We observe how the circuit is parametrized by the coefficients of eq. (\ref {coeff Z}).}}{15}{}\protected@file@percent }
\newlabel{fig:Z}{{5}{15}{}{}{}}
\newlabel{coeff ZZ1}{{42}{16}{}{}{}}
\newlabel{coeff ZZ2}{{43}{16}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces ZZ feature map, with 2 qubits and 2 features, decomposed in terms of elementary gates. The gate $P$ is defined as $P(\phi ) = (1,0; 0, e^{i\phi })$. We observe how the circuit is parametrized by the coefficients of eq. (\ref {coeff ZZ1}) and (\ref {coeff ZZ2}).}}{16}{}\protected@file@percent }
\newlabel{fig:ZZ}{{6}{16}{}{}{}}
\newlabel{pauli}{{45}{16}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Pauli feature map, with 2 qubits and 2 features, decomposed in term of elementary gates, constructed with Y and YZ interactions.}}{17}{}\protected@file@percent }
\newlabel{fig:Pauli}{{7}{17}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.3}QSVM algorithm and Qiskit implementation}{17}{}\protected@file@percent }
\newlabel{circuit item }{{46}{18}{}{}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Quantum Support Vector Machine (QSVM)}}{19}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces QSVM decision boundary with ZFeatureMap, fitted on a 2 feature mock dataset of 200 instances.}}{20}{}\protected@file@percent }
\newlabel{fig:qsvm}{{8}{20}{}{}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.4}QSVM potential}{20}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Artificial ad hoc dataset, generated with $\Delta =0.3$. This dataset, by construction, is easily separable by ZZFeatureMap.}}{21}{}\protected@file@percent }
\newlabel{fig:adhoc}{{9}{21}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Result of the classical fit with RBF kernel on the artificial dataset. We observe how the SVM could not find the correct separation between the classes. }}{22}{}\protected@file@percent }
\newlabel{fig:adhocrbf}{{10}{22}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Result of the quantum fit on the artificial dataset, with ZZFeatureMap. We observe how the QSVM found the correct separation between the classes.}}{23}{}\protected@file@percent }
\newlabel{fig:adhoczz}{{11}{23}{}{}{}}
\gdef \@abspage@last{23}
