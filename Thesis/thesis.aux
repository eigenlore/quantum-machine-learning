\relax 
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\babel@aux{english}{}
\citation{biamonte2017}
\citation{havlicek2019}
\citation{schuld2018}
\citation{cristianini2000}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Classical Support Vector Machine}{4}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}General overview}{4}{subsection.2.1}\protected@file@percent }
\citation{cristianini2000}
\citation{cristianini2000}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Support vector machine}{5}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Linear SVM}{6}{subsubsection.2.2.1}\protected@file@percent }
\newlabel{margin definition}{{1}{6}{Linear SVM}{equation.2.1}{}}
\newlabel{constraint hard margin}{{5}{7}{Linear SVM}{equation.2.5}{}}
\newlabel{alpha def}{{6}{7}{Linear SVM}{equation.2.6}{}}
\newlabel{dual problem SVM}{{7}{7}{Linear SVM}{equation.2.7}{}}
\citation{cristianini2000}
\citation{pedregosa2011}
\newlabel{decision boundary svm}{{11}{8}{Linear SVM}{equation.2.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces SVM decision boundary and margin border, fitted on a 2 feature mock dataset of 200 instances.}}{9}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:classical svm mock}{{1}{9}{SVM decision boundary and margin border, fitted on a 2 feature mock dataset of 200 instances}{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.2}Kernel SVM}{10}{subsubsection.2.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Higly non-linear 2 feature mock dataset with 200 instances.}}{10}{figure.caption.3}\protected@file@percent }
\newlabel{fig:classical svm circles}{{2}{10}{Higly non-linear 2 feature mock dataset with 200 instances}{figure.caption.3}{}}
\newlabel{kernel max}{{16}{11}{Kernel SVM}{equation.2.16}{}}
\newlabel{kernel prodiction}{{17}{11}{Kernel SVM}{equation.2.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Highly non-linear mock dataset in the feature space after the application of the feature map $\phi $. We observe now that the dataset is linearly separable.}}{12}{figure.caption.4}\protected@file@percent }
\newlabel{fig:classical svm circle 3d}{{3}{12}{Highly non-linear mock dataset in the feature space after the application of the feature map $\phi $. We observe now that the dataset is linearly separable}{figure.caption.4}{}}
\newlabel{kernel max K}{{19}{12}{Kernel SVM}{equation.2.19}{}}
\newlabel{kernel prodiction K}{{20}{13}{Kernel SVM}{equation.2.20}{}}
\newlabel{polykernel ex}{{21}{13}{Kernel SVM}{equation.2.21}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Highly non-linear mock dataset decision boundary, fitted with a SVM using kernel of eq. (\ref {polykernel ex}). The white and black areas are the two predicted classes. We observe how, using this kernel, we obtain a non-linear decision boundary.}}{15}{figure.caption.5}\protected@file@percent }
\newlabel{fig:classical svm circle decision boundary}{{4}{15}{Highly non-linear mock dataset decision boundary, fitted with a SVM using kernel of eq. (\ref {polykernel ex}). The white and black areas are the two predicted classes. We observe how, using this kernel, we obtain a non-linear decision boundary}{figure.caption.5}{}}
\citation{havlicek2019}
\citation{schuld2018}
\citation{park2020}
\@writefile{toc}{\contentsline {section}{\numberline {3}Quantum Support Vector Machine}{16}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}General overview}{16}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Quantum feature map and Quantum Kernels}{16}{subsection.3.2}\protected@file@percent }
\newlabel{circuit}{{26}{18}{Quantum feature map and Quantum Kernels}{equation.3.26}{}}
\newlabel{frequency}{{27}{18}{Quantum feature map and Quantum Kernels}{equation.3.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Quantum encoding circuits}{19}{subsection.3.3}\protected@file@percent }
\newlabel{ZZ}{{37}{22}{Quantum encoding circuits}{equation.3.37}{}}
\newlabel{coeff Z}{{39}{23}{Quantum encoding circuits}{equation.3.39}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Z feature map, with 2 qubits and 2 features, decomposed in terms of elementary gates. The gate $P$ is defined as $P(\phi ) = (1,0; 0, e^{i\phi })$, where $\phi $ is the parameter of the gate, and in our case can either be $2x_0$ or $2x_1$. We observe how the circuit is parametrized by the coefficients of eq. (\ref {coeff Z}).}}{23}{figure.caption.6}\protected@file@percent }
\newlabel{fig:Z}{{5}{23}{Z feature map, with 2 qubits and 2 features, decomposed in terms of elementary gates. The gate $P$ is defined as $P(\phi ) = (1,0; 0, e^{i\phi })$, where $\phi $ is the parameter of the gate, and in our case can either be $2x_0$ or $2x_1$. We observe how the circuit is parametrized by the coefficients of eq. (\ref {coeff Z})}{figure.caption.6}{}}
\newlabel{coeff ZZ1}{{42}{23}{Quantum encoding circuits}{equation.3.42}{}}
\newlabel{coeff ZZ2}{{43}{23}{Quantum encoding circuits}{equation.3.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces ZZ feature map, with 2 qubits and 2 features, decomposed in terms of elementary gates. The gate $P$ is defined as $P(\phi ) = (1,0; 0, e^{i\phi })$, where $\phi $ is the parameter of the gate. The values that the parameter take are shown in the Figure, according to eq. (\ref {coeff ZZ1}) and (\ref {coeff ZZ2}).}}{24}{figure.caption.7}\protected@file@percent }
\newlabel{fig:ZZ}{{6}{24}{ZZ feature map, with 2 qubits and 2 features, decomposed in terms of elementary gates. The gate $P$ is defined as $P(\phi ) = (1,0; 0, e^{i\phi })$, where $\phi $ is the parameter of the gate. The values that the parameter take are shown in the Figure, according to eq. (\ref {coeff ZZ1}) and (\ref {coeff ZZ2})}{figure.caption.7}{}}
\newlabel{pauli}{{45}{24}{Quantum encoding circuits}{equation.3.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Pauli feature map, with 2 qubits and 2 features, decomposed in term of elementary gates, constructed with Y and YZ interactions.}}{25}{figure.caption.8}\protected@file@percent }
\newlabel{fig:Pauli}{{7}{25}{Pauli feature map, with 2 qubits and 2 features, decomposed in term of elementary gates, constructed with Y and YZ interactions}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}QSVM algorithm and Qiskit implementation}{25}{subsection.3.4}\protected@file@percent }
\newlabel{circuit item }{{46}{26}{QSVM algorithm and Qiskit implementation}{equation.3.46}{}}
\newlabel{loss function}{{48}{27}{QSVM algorithm and Qiskit implementation}{equation.3.48}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Quantum Support Vector Machine (QSVM)}}{28}{algorithm.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}QSVM potential}{29}{subsection.3.5}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces QSVM decision boundary with ZFeatureMap, fitted on a 2 feature mock dataset of 200 instances.}}{30}{figure.caption.9}\protected@file@percent }
\newlabel{fig:qsvm}{{8}{30}{QSVM decision boundary with ZFeatureMap, fitted on a 2 feature mock dataset of 200 instances}{figure.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Artificial ad hoc dataset, generated with $\Delta =0.3$. This dataset, by construction, is easily separable by ZZFeatureMap.}}{31}{figure.caption.10}\protected@file@percent }
\newlabel{fig:adhoc}{{9}{31}{Artificial ad hoc dataset, generated with $\Delta =0.3$. This dataset, by construction, is easily separable by ZZFeatureMap}{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Result of the classical fit with RBF kernel on the artificial dataset. We observe how the SVM could not find the correct separation between the classes. }}{32}{figure.caption.11}\protected@file@percent }
\newlabel{fig:adhocrbf}{{10}{32}{Result of the classical fit with RBF kernel on the artificial dataset. We observe how the SVM could not find the correct separation between the classes}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Issues of QSVM}{32}{subsection.3.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Result of the quantum fit on the artificial dataset, with ZZFeatureMap. We observe how the QSVM found the correct separation between the classes.}}{33}{figure.caption.12}\protected@file@percent }
\newlabel{fig:adhoczz}{{11}{33}{Result of the quantum fit on the artificial dataset, with ZZFeatureMap. We observe how the QSVM found the correct separation between the classes}{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Circle dataset fitted with PauliFeatureMap leads to a very inaccurate decision boundary.}}{34}{figure.caption.13}\protected@file@percent }
\newlabel{fig:failcircle}{{12}{34}{Circle dataset fitted with PauliFeatureMap leads to a very inaccurate decision boundary}{figure.caption.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Quantum kernel alignment}{35}{subsection.3.7}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Circuit optimization}{35}{subsubsection.3.7.1}\protected@file@percent }
\newlabel{qka}{{52}{35}{Circuit optimization}{equation.3.52}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Parametrized quantum circuit, with two rotation inserted before a ZZFeatureMap.}}{38}{figure.caption.14}\protected@file@percent }
\newlabel{fig:param rotation}{{13}{38}{Parametrized quantum circuit, with two rotation inserted before a ZZFeatureMap}{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Parametrized quantum circuit, with a ZZFeatureMap inserted before another ZZFeatureMap. The former has the parameters $\lambda $ for Quantum Kernel Alignment, while the latter has the parameters $\mathbf  {x}$ in order to encode the classical instance.}}{38}{figure.caption.15}\protected@file@percent }
\newlabel{fig:ZZafterZZ}{{14}{38}{Parametrized quantum circuit, with a ZZFeatureMap inserted before another ZZFeatureMap. The former has the parameters $\lambda $ for Quantum Kernel Alignment, while the latter has the parameters $\mathbf {x}$ in order to encode the classical instance}{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.2}Performance}{39}{subsubsection.3.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Result of the fit of circular dataset using QKA-QSVM. An accuracy of 50\% is achieved.}}{40}{figure.caption.16}\protected@file@percent }
\newlabel{fig:qka}{{15}{40}{Result of the fit of circular dataset using QKA-QSVM. An accuracy of 50\% is achieved}{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces On the left convergence of the loss function during the QKA training. On the right the final trained kernel matrix.}}{40}{figure.caption.17}\protected@file@percent }
\newlabel{fig:loss function}{{16}{40}{On the left convergence of the loss function during the QKA training. On the right the final trained kernel matrix}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Genetic algorithm}{42}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}General introduction}{42}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Genetic algorithm for QSVM}{43}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Example of the phenotype of an individual. The phenotype is a quantum circuit.}}{46}{figure.caption.18}\protected@file@percent }
\newlabel{fig:fenotip}{{17}{46}{Example of the phenotype of an individual. The phenotype is a quantum circuit}{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces First parent phenotype.}}{47}{figure.caption.19}\protected@file@percent }
\newlabel{fig:1par}{{18}{47}{First parent phenotype}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Second parent phenotype.}}{47}{figure.caption.19}\protected@file@percent }
\newlabel{fig:2par}{{19}{47}{Second parent phenotype}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces First child phenotype.}}{47}{figure.caption.19}\protected@file@percent }
\newlabel{fig:1child}{{20}{47}{First child phenotype}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Second child phenotype.}}{47}{figure.caption.19}\protected@file@percent }
\newlabel{fig:2child}{{21}{47}{Second child phenotype}{figure.caption.19}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Starting non mutated individual.}}{48}{figure.caption.20}\protected@file@percent }
\newlabel{fig:mutated}{{22}{48}{Starting non mutated individual}{figure.caption.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces Mutated individual. The first gene is mutated from a $\sqrt  {X}$ acting on the first qubit into an $R_z$ acting again on the first qubit. The other genes in this case were not mutated.}}{48}{figure.caption.20}\protected@file@percent }
\newlabel{fig:nonmutated}{{23}{48}{Mutated individual. The first gene is mutated from a $\sqrt {X}$ acting on the first qubit into an $R_z$ acting again on the first qubit. The other genes in this case were not mutated}{figure.caption.20}{}}
\newlabel{accuracy}{{59}{49}{Genetic algorithm for QSVM}{equation.4.59}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {24}{\ignorespaces Fitness of an individual as a function of its accuracy on the test set. This choice is made to properly penalize bad performing individuals.}}{50}{figure.caption.21}\protected@file@percent }
\newlabel{fig:fitness function}{{24}{50}{Fitness of an individual as a function of its accuracy on the test set. This choice is made to properly penalize bad performing individuals}{figure.caption.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Results}{52}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Circle dataset}{52}{subsubsection.4.3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Parameters of the genetic algorithm}}{54}{table.caption.22}\protected@file@percent }
\newlabel{tabella accettanza}{{1}{54}{Parameters of the genetic algorithm}{table.caption.22}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {25}{\ignorespaces Final circuit of the genetic algorithm. This is the phenotype of the best individual of the last generation. This is the circuit with the best performance on this dataset that the genetic algorithm could find.}}{54}{figure.caption.23}\protected@file@percent }
\newlabel{fig:final circuit}{{25}{54}{Final circuit of the genetic algorithm. This is the phenotype of the best individual of the last generation. This is the circuit with the best performance on this dataset that the genetic algorithm could find}{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {26}{\ignorespaces Mean accuracy of each generation. We observe a consistent increase of the accuracy, ensuring that the genetic algorithm is improving the performance of the feature maps from generation to generation.}}{55}{figure.caption.24}\protected@file@percent }
\newlabel{fig:mean accuracy}{{26}{55}{Mean accuracy of each generation. We observe a consistent increase of the accuracy, ensuring that the genetic algorithm is improving the performance of the feature maps from generation to generation}{figure.caption.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {27}{\ignorespaces Final test of the resulting circuit of the genetic algorithm on a new dataset with respect the one it was trained on. The fact that the circuit is well performing on this dataset indicates that we actually found a circuit well performing on this sort of datasets.}}{56}{figure.caption.25}\protected@file@percent }
\newlabel{fig:awesome}{{27}{56}{Final test of the resulting circuit of the genetic algorithm on a new dataset with respect the one it was trained on. The fact that the circuit is well performing on this dataset indicates that we actually found a circuit well performing on this sort of datasets}{figure.caption.25}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {28}{\ignorespaces Test of the performance of an individual from the first generation on the same dataset. We observe how its performance is very low, indicating that the first generation of individuals performs poorly as we expected.}}{57}{figure.caption.26}\protected@file@percent }
\newlabel{fig:bad}{{28}{57}{Test of the performance of an individual from the first generation on the same dataset. We observe how its performance is very low, indicating that the first generation of individuals performs poorly as we expected}{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {29}{\ignorespaces Test of the performance of the best individual on a new dataset with noise. The circuit is revealed to be robust against noise, correctly classifying 91\% of the point.}}{58}{figure.caption.27}\protected@file@percent }
\newlabel{fig:noise}{{29}{58}{Test of the performance of the best individual on a new dataset with noise. The circuit is revealed to be robust against noise, correctly classifying 91\% of the point}{figure.caption.27}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Moon dataset}{58}{subsubsection.4.3.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {30}{\ignorespaces Final circuit of the genetic algorithm used on the moon dataset.}}{59}{figure.caption.28}\protected@file@percent }
\newlabel{fig:mooncircuit}{{30}{59}{Final circuit of the genetic algorithm used on the moon dataset}{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {31}{\ignorespaces Performance of the final circuit on the moon dataset. Even in this case a good accuracy is achieved.}}{59}{figure.caption.29}\protected@file@percent }
\newlabel{fig:moonboh}{{31}{59}{Performance of the final circuit on the moon dataset. Even in this case a good accuracy is achieved}{figure.caption.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{60}{section.5}\protected@file@percent }
\bibcite{biamonte2017}{1}
\bibcite{havlicek2019}{2}
\bibcite{cristianini2000}{3}
\bibcite{pedregosa2011}{4}
\bibcite{ivezic1994}{5}
\bibcite{mitchell1999}{6}
\bibcite{eiben2003}{7}
\bibcite{sunckel2023}{8}
\bibcite{creevey2023a}{9}
\bibcite{creevey2023b}{10}
\bibcite{hubregtsen2021}{11}
\bibcite{glick2022}{12}
\bibcite{schuld2021a}{13}
\bibcite{zhou2024}{14}
\bibcite{lloyd2022}{15}
\bibcite{schuld2021b}{16}
\bibcite{innan2023}{17}
\bibcite{schuld2018}{18}
\bibcite{yang2019}{19}
\bibcite{liu2020}{20}
\bibcite{rebentrost2014}{21}
\bibcite{park2020}{22}
\gdef \@abspage@last{63}
